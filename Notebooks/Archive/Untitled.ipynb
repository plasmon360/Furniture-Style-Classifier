{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import fastai\n",
    "\n",
    "assert(torch.__version__ == '1.1.0')\n",
    "assert(torchvision.__version__== '0.3.0')\n",
    "assert(fastai.__version__ == '1.0.55')\n",
    "\n",
    "\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision.models import resnet34 as resnet\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.modules import Module\n",
    "\n",
    "\n",
    "from pytorch_utils.hooks import hook_context_manager\n",
    "from pytorch_utils.callbacks import MyLrFinder, RecordMetric\n",
    "from pytorch_utils.trainer import learn\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets.folder import ImageFolder, default_loader, IMG_EXTENSIONS, make_dataset\n",
    "from torch.utils.data.dataset import Subset, random_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class Furniture_Dataset(ImageFolder):\n",
    "    '''\n",
    "    Custom Dataset from ImageFolder with subset of classes defined by classes_for_consideration.\n",
    "    If classes_for_consideration = None, then all classes are choosen.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, root, transform, classes_for_consideration = None):\n",
    "        super().__init__(root, transform = transform)\n",
    "        \n",
    "        if classes_for_consideration:\n",
    "           # check if the classes in classes_for_consideration are part of available classes deteced by DatasetFolder in the root folder\n",
    "            if all([_ in self.classes for _ in classes_for_consideration]):\n",
    "                classes, class_to_idx = classes_for_consideration, {classes_for_consideration[i]: i for i in range(len(classes_for_consideration))}\n",
    "                samples = make_dataset(self.root, class_to_idx, extensions = IMG_EXTENSIONS)\n",
    "                self.classes = classes\n",
    "                self.class_to_idx = class_to_idx\n",
    "                self.samples = samples\n",
    "                self.targets = [s[1] for s in samples]\n",
    "            else:\n",
    "                print(\"Certain class in classes_for_consideration is not available in possible classes. Check your classes_for_consideration. Choosing all classes instead\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trfms = {}\n",
    "trfms['train'] = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                           transforms.RandomHorizontalFlip(),\n",
    "                                            transforms.RandomVerticalFlip(),\n",
    "                                            transforms.RandomRotation(10),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize(*imagenet_stats)])\n",
    "\n",
    "trfms['val'] = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize(*imagenet_stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import  get_transforms, imagenet_stats\n",
    "\n",
    "\n",
    "\n",
    "all_data = Furniture_Dataset(root = Path('../Data'),transform = trfms,\n",
    "#             classes_for_consideration = ['arts_and_crafts', 'mid-century-modern', 'rustic', 'traditional'])\n",
    "                                            classes_for_consideration = None,\n",
    "                            )\n",
    "\n",
    "\n",
    "\n",
    "#Create random split and create indices for train and val\n",
    "indices = {}\n",
    "# torch.manual_seed(1)\n",
    "random_indices = torch.randperm(len(all_data))\n",
    "valid_pct = .25\n",
    "\n",
    "split = int((1-valid_pct)*len(random_indices))\n",
    "\n",
    "if split%2:\n",
    "    split = split-1\n",
    "    \n",
    "indices['train']= random_indices[:split]\n",
    "indices['val'] = random_indices[split:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets ={}\n",
    "data = {}\n",
    "batch_size = 32\n",
    "\n",
    "val_train_ratio = 0.2\n",
    "val_length = int(val_train_ratio*len(all_data))\n",
    "train_length = len(all_data) - val_length\n",
    "\n",
    "\n",
    "\n",
    "datasets['train'], datasets['val'] = random_split(all_data, [train_length, val_length])\n",
    "\n",
    "for datatype in ['train','val']:\n",
    "    # Dataloader\n",
    "    data[datatype] = torch.utils.data.DataLoader(datasets[datatype], batch_size, num_workers=4, shuffle = True)\n",
    "\n",
    "data['classes'] = all_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def show_batch(dataloader, plot_num = None):\n",
    "    \n",
    "    inputs, classes = next(iter(dataloader))\n",
    "    \n",
    "    classes = classes.tolist()\n",
    "    \n",
    "    # denormalization\n",
    "    mean, std = imagenet_stats\n",
    "    std = torch.tensor(std)\n",
    "    mean = torch.tensor(mean)\n",
    "    inputs = inputs.mul(std[None,:,None,None])+mean[None,:,None,None]\n",
    "\n",
    "    if (not plot_num) or (plot_num > inputs.shape[0]):\n",
    "        plot_num = inputs.shape[0]\n",
    "    \n",
    "    ncols = 4\n",
    "    nrows = math.ceil(plot_num/ncols)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows, ncols)\n",
    "    ax = ax.ravel()\n",
    "        \n",
    "    for img in range(plot_num):\n",
    "        ax[img].imshow(inputs[img,...].permute(1,2,0))  \n",
    "        ax[img].set_title(dataloader.dataset.subset.classes[classes[img]])\n",
    "\n",
    "    for _ in ax:\n",
    "        _.axis('off')\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
